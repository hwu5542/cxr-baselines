import csv
import numpy as np
import pandas as pd
import os
import random
import gc
import tracemalloc
import time
from pathlib import Path
from memory_profiler import profile
from loader import Loader
from stages import Extractor, Classifier, Aggregator

def log_memory_usage(prefix=""):
    """Log current memory usage statistics"""
    allocated, peak = tracemalloc.get_traced_memory()
    print(f"{prefix} Memory - Current: {allocated / 1024:.2f} KB, Peak: {peak / 1024:.2f} KB")

def memory_intensive_operation_wrapper(func):
    """Decorator to monitor memory usage of specific operations"""
    def wrapper(*args, **kwargs):
        tracemalloc.start()
        start_time = time.time()
        
        result = func(*args, **kwargs)
        
        end_time = time.time()
        log_memory_usage(f"During {func.__name__}")
        tracemalloc.stop()
        
        print(f"{func.__name__} executed in {end_time - start_time:.2f} seconds")
        return result
    return wrapper

@profile
def evaluate_chexpert(predictions_df: pd.DataFrame, report_text, output_dir, suffix=""):
    """
    Evaluate reports using CheXpert pipeline with memory leak analysis
    
    Args:
        predictions_df: DataFrame containing reports
        report_text: Column name containing report text
        output_dir: Directory to save output
        suffix: Optional suffix for output files
    """
    # Initialize memory tracking
    tracemalloc.start()
    log_memory_usage("Initial")
    
    try:
        # Initialize CheXpert components
        extractor = Extractor(
            Path("negbio/chexpert/phrases/mention"),
            Path("negbio/chexpert/phrases/unmention"),
            False,
        )
        log_memory_usage("After extractor init")

        classifier = Classifier(
            "negbio/chexpert/patterns/pre_negation_uncertainty.txt",
            "negbio/chexpert/patterns/negation.txt",
            "negbio/chexpert/patterns/post_negation_uncertainty.txt",
            verbose=True,
        )
        log_memory_usage("After classifier init")

        CATEGORIES = [
            "No Finding",
            "Enlarged Cardiomediastinum",
            "Cardiomegaly",
            "Lung Lesion",
            "Lung Opacity",
            "Edema",
            "Consolidation",
            "Pneumonia",
            "Atelectasis",
            "Pneumothorax",
            "Pleural Effusion",
            "Pleural Other",
            "Fracture",
            "Support Devices",
        ]

        aggregator = Aggregator(CATEGORIES, False)
        log_memory_usage("After aggregator init")

        @memory_intensive_operation_wrapper
        def process_reports():
            """Helper function to process reports through CheXpert pipeline"""
            tempname = f"/tmp/chexpert-reports-{random.randint(0,10**6)}{suffix}.csv"
            
            # Memory efficient CSV writing
            predictions_df[report_text].to_csv(
                tempname, index=False, header=False, quoting=csv.QUOTE_ALL
            )
            log_memory_usage("After CSV write")

            loader = Loader(tempname, False, False)
            loader.load()
            log_memory_usage("After loader load")

            extractor.extract(loader.collection)
            log_memory_usage("After extract")

            classifier.classify(loader.collection)
            log_memory_usage("After classify")

            labels = aggregator.aggregate(loader.collection)
            log_memory_usage("After aggregate")

            try:
                os.remove(tempname)
            except Exception as e:
                print(f"Warning: Could not remove temp file {tempname}: {str(e)}")

            return labels

        labels = process_reports()

        # Memory efficient DataFrame creation
        labels_df = pd.DataFrame(labels, columns=CATEGORIES)
        log_memory_usage("After DataFrame creation")

        # Ensure output directory exists
        os.makedirs(output_dir, exist_ok=True)
        
        # Write output
        output_path = f"{output_dir}/chexpert_labels{suffix}.csv"
        labels_df.to_csv(output_path, index=False)
        log_memory_usage("After CSV output")

    finally:
        # Clean up and report final memory status
        snapshot = tracemalloc.take_snapshot()
        top_stats = snapshot.statistics('lineno')
        
        print("\nMemory allocation hotspots:")
        for stat in top_stats[:10]:  # Show top 10
            print(stat)
        
        tracemalloc.stop()
        
        # Explicit cleanup
        del extractor, classifier, aggregator
        if 'labels_df' in locals():
            del labels_df
        gc.collect()
        log_memory_usage("Final cleanup")

if __name__ == "__main__":
    # Example usage with memory profiling
    test_df = pd.DataFrame({
        "report_text": ["No acute cardiopulmonary abnormality.", "Lung opacity seen."]
    })
    evaluate_chexpert(test_df, "report_text", "./output")